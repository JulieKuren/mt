{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import pattern.en as en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ./utils.ipynb\n",
    "%run ./nlp.ipynb\n",
    "%run ./relation_extraction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# text, relations = extract_relations(\n",
    "#     \"parsed/race/train/middle/3260.txt.tree\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_segment(text, relation, direction):\n",
    "    if direction == \"left\":\n",
    "        child, segment = relation.left_child, relation.left\n",
    "    else:\n",
    "        child, segment = relation.right_child, relation.right\n",
    "    if child:\n",
    "        return search_segment(\n",
    "            text, \n",
    "            child, \n",
    "            direction\n",
    "        )\n",
    "    else:\n",
    "        return text[segment.start:segment.end]\n",
    "    \n",
    "    \n",
    "def get_depth(relation):\n",
    "    if relation:\n",
    "        return 1 + max(\n",
    "            get_depth(relation.left_child), \n",
    "            get_depth(relation.right_child)\n",
    "        )\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_attribution(relation):\n",
    "    return relation is not None and relation.type == \"Attribution\"\n",
    "\n",
    "\n",
    "def has_nested_attribution(relation):\n",
    "    return (\n",
    "        (\n",
    "            relation.left == \"N\" and is_attribution(relation.left_child)\n",
    "        )\n",
    "        or (\n",
    "            relation.right == \"N\" and is_attribution(relation.right_child)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return [t.lower() for t in word_tokenize(s)]\n",
    "\n",
    "\n",
    "def get_first_token(s):\n",
    "    tokenized = word_tokenize(s)\n",
    "    if len(tokenized) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return tokenized[0].lower()\n",
    "    \n",
    "\n",
    "def normalise_verb(verb):\n",
    "    return en.conjugate(\n",
    "        verb, \n",
    "        tense = en.PRESENT,        # INFINITIVE, PRESENT, PAST, FUTURE\n",
    "        person = 1,              # 1, 2, 3 or None\n",
    "        number = en.SINGULAR,       # SG, PL\n",
    "        mood = en.INDICATIVE,     # INDICATIVE, IMPERATIVE, CONDITIONAL, SUBJUNCTIVE\n",
    "        negated = False,          # True or False\n",
    "        parse = True\n",
    "    )\n",
    "\n",
    "\n",
    "class SpeechVerbFinder:\n",
    "    def __init__(self):\n",
    "        with open(\"speech_verbs.txt\", \"rt\") as f:\n",
    "            self.speech_verbs = {line.strip().lower() for line in f.readlines()}\n",
    "    \n",
    "    def find_speech_verb(self, tokens):\n",
    "        found_verbs = self.speech_verbs.intersection({normalise_verb(t) for t in tokens})\n",
    "        if len(found_verbs) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return list(found_verbs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_plural(word):\n",
    "    if word == en.pluralize(word):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conjugate(verb):\n",
    "    return en.conjugate(verb, tense=en.PAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speech_verb_finder = SpeechVerbFinder()\n",
    "\n",
    "\n",
    "def extract_nuclei(\n",
    "    nucleus_relation,\n",
    "    nucleus_segment,\n",
    "    satellite_relation,\n",
    "    satellite_nucleus_relation,\n",
    "    satellite_nucleus_segment,\n",
    "    nucleus_direction\n",
    "):\n",
    "    # if there are nested relations in the nucleus\n",
    "    # and there are too many of them\n",
    "    if nucleus_relation and get_depth(nucleus_relation) > 3:\n",
    "        nucleus_text = clean( \n",
    "            search_segment( # take the closest nested segment relative to the satellite\n",
    "                text, \n",
    "                nucleus_relation,\n",
    "                nucleus_direction\n",
    "            )\n",
    "        )\n",
    "    else: # else take the nucleus as is\n",
    "        nucleus_text = clean(\n",
    "            text[nucleus_segment.start:nucleus_segment.end]\n",
    "        )   \n",
    "\n",
    "    # checking if the nucleus of the satellite is on the right/left\n",
    "    if satellite_relation.left.type == \"N\":\n",
    "        satellite_nucleus_relation = satellite_relation.left_child\n",
    "        satellite_nucleus_segment = satellite_relation.left\n",
    "        if nucleus_direction == \"right\": # if the expl. nucleus is on the left\n",
    "            nucleus_proximity = \"near\"\n",
    "        else:\n",
    "            nucleus_proximity = \"far\"\n",
    "    else:\n",
    "        satellite_nucleus_relation = satellite_relation.right_child\n",
    "        satellite_nucleus_segment = satellite_relation.right\n",
    "        if nucleus_direction == \"right\":\n",
    "            nucleus_proximity = \"far\"\n",
    "        else:\n",
    "            nucleus_proximity = \"near\"\n",
    "\n",
    "    # if there are nested relations in the satellite nucleus\n",
    "    # and there are too many of them\n",
    "    if (\n",
    "        satellite_nucleus_relation \n",
    "        and get_depth(satellite_nucleus_relation) > 3\n",
    "    ):\n",
    "        satellite_nucleus_text = clean(\n",
    "            search_segment(# take the closest nested segment relative to the nucleus\n",
    "                text, \n",
    "                satellite_nucleus_relation, \n",
    "                satellite_direction\n",
    "            )\n",
    "        )\n",
    "    else: # else take the satellite nucleus as is\n",
    "        satellite_nucleus_text = clean(\n",
    "            text[\n",
    "                satellite_nucleus_segment.start\n",
    "                :satellite_nucleus_segment.end\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return nucleus_text, satellite_nucleus_text, nucleus_proximity\n",
    "\n",
    "            \n",
    "def rule_explanation_02(text, relation):\n",
    "    assert(relation is not None and relation.type == \"Explanation\")\n",
    "    if relation.left.type == \"N\":\n",
    "        nucleus_direction = \"right\"\n",
    "        nucleus_relation = relation.left_child\n",
    "        nucleus_segment = relation.left\n",
    "        satellite_relation = relation.right_child\n",
    "        satellite_segment = relation.right\n",
    "    else:\n",
    "        nucleus_direction = \"left\"\n",
    "        nucleus_relation = relation.right_child\n",
    "        nucleus_segment = relation.right\n",
    "        satellite_relation = relation.left_child\n",
    "        satellite_segment = relation.left\n",
    "    \n",
    "    if satellite_relation is None:\n",
    "        return None, None\n",
    "    \n",
    "    sn_relation, sn_segment = satellite_relation.get_first_nucleus()\n",
    "    \n",
    "    if sn_segment is None:\n",
    "        return None, None\n",
    "    \n",
    "    nucleus_text, satellite_nucleus_text, nucleus_proximity = extract_nuclei(\n",
    "        nucleus_relation,\n",
    "        nucleus_segment,\n",
    "        satellite_relation,\n",
    "        sn_relation,\n",
    "        sn_segment,\n",
    "        nucleus_direction\n",
    "    )\n",
    "    \n",
    "    _, ss_segment = satellite_relation.get_satellite()\n",
    "    if ss_segment is not None:\n",
    "        ss_tokens = tokenize(text[ss_segment.start:ss_segment.end])\n",
    "        satellite_speech_verb = speech_verb_finder.find_speech_verb(ss_tokens)\n",
    "        if satellite_speech_verb is not None:\n",
    "            new_st, sent_no = move_st(text, ss_segment.start, 5)\n",
    "            resolved_subjects = get_resolved_subjects(text[new_st:ss_segment.end])\n",
    "            if len(resolved_subjects) > 0:\n",
    "                resolved_subject = resolved_subjects[-1]\n",
    "                if resolved_subject is not None:\n",
    "                    statement = \"{nucleus}. That is why {subject} {verb} {satellite_nucleus}\".format(\n",
    "                        nucleus=remove_trailing_punctuation(\n",
    "                            uppercase_first_letter(nucleus_text)\n",
    "                        ),\n",
    "                        subject=resolved_subject,\n",
    "                        verb=conjugate(satellite_speech_verb),\n",
    "                        satellite_nucleus=satellite_nucleus_text\n",
    "                    )\n",
    "                    return statement, nucleus_proximity\n",
    "                \n",
    "    if (\n",
    "        get_first_token(text[satellite_segment.start:satellite_segment.end]) == \"so\"\n",
    "        or (\n",
    "            nucleus_relation is None \n",
    "            and satellite_relation is not None\n",
    "            and (\n",
    "                    satellite_relation.type in {\"Joint\", \"Elaboration\", \"Attribution\"}\n",
    "                    or (\n",
    "                        satellite_relation.type == \"Explanation\" \n",
    "                        and has_nested_attribution(satellite_relation)\n",
    "                    )\n",
    "            )\n",
    "        )\n",
    "        or (\n",
    "            nucleus_relation is not None\n",
    "            and satellite_relation is not None\n",
    "            and (\n",
    "                (\n",
    "                    nucleus_relation.type == \"Elaboration\"\n",
    "                    and satellite_relation.type == \"Attribution\"\n",
    "                )\n",
    "                or (\n",
    "                    nucleus_relation.type == \"Background\"\n",
    "                    and satellite_relation.type == \"Explanation\"\n",
    "                )\n",
    "                or (\n",
    "                    nucleus_relation.type == \"Joint\"\n",
    "                    and satellite_relation.type in {\"Elaboration\", \"Attribution\", \"Explanation\"}\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ):\n",
    "        statement = \"{nucleus}. That is why {satellite_nucleus}\".format(\n",
    "            nucleus=remove_trailing_punctuation(\n",
    "                uppercase_first_letter(nucleus_text)\n",
    "            ),\n",
    "            satellite_nucleus=satellite_nucleus_text\n",
    "        )\n",
    "        return statement, nucleus_proximity\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"parsed/race/train/middle/3260.txt.tree\", \"rt\") as f:\n",
    "    tree_text = f.read()\n",
    "\n",
    "text, relations = read_relations(tree_text.replace(\"<s>\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After the game , Wu Nai , head of the boys \\' team , was very unhappy .  \" We all thought this would be an easy game , \" he said .  '"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl = relations[\"Explanation\"][0]\n",
    "text[expl.left.start:expl.right.end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('After the game, Wu Nai, head of the boys\\' team, was very unhappy. That is why he said \" We all thought this would be an easy game, \"',\n",
       " 'near')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rule_explanation_02(text, expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"parsed/race/train/middle/5646.txt.tree\", \"rt\") as f:\n",
    "    tree_text = f.read()\n",
    "\n",
    "text, relations = read_relations(tree_text.replace(\"<s>\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I landed on a piece of glass that cut my eye badly . from then on , my injured , sightless , cloudy gray eye lived on with me .  Sometimes people asked me embarrassing questions .  Whenever kids played games , I was the \" monster \" . I was always imagining that everyone looked down on me .  Yet mum would say to me , \" Hold your head up high and face the world . \"  '"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl = relations[\"Explanation\"][0]\n",
    "text[expl.left.start:expl.right.end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I landed on a piece of glass that cut my eye badly. from then on, my injured, sightless, cloudy gray eye lived on with me. That is why mum said Sometimes people asked me embarrassing questions.',\n",
       " 'near')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " rule_explanation_02(text, expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I say it to my children .  The gift my mum gave me will live on . <P> '"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl = relations[\"Explanation\"][2]\n",
    "text[expl.left.start:expl.right.end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I say it to my children. That is why me will live on.', 'far')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_explanation_02(text, expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"parsed/race/train/middle/293.txt.tree\", \"rt\") as f:\n",
    "    tree_text = f.read()\n",
    "\n",
    "text, relations = read_relations(tree_text.replace(\"<s>\", \"\").replace(\"<P>\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Matt asked .  \" Friends and patience . \" he answered .  '"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl = relations[\"Explanation\"][1]\n",
    "text[expl.left.start:expl.right.end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Matt asked. That is why Matt answered \" Friends and patience. \"', 'near')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_explanation_02(text, expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DIRECTORY = \"parsed/race/train/middle\"\n",
    "\n",
    "# statements_near, statements_far = [], []\n",
    "# for file_name in os.listdir(DIRECTORY):\n",
    "#     path = os.path.join(DIRECTORY, file_name)\n",
    "#     text, relations = extract_relations(path)\n",
    "    \n",
    "#     if \"Explanation\" in relations:\n",
    "#         for relation in relations[\"Explanation\"]:\n",
    "#             statement, nucleus_proximity = rule_explanation_elaboration(\n",
    "#                 text, \n",
    "#                 relation\n",
    "#             )\n",
    "#             if statement is not None:\n",
    "#                 statement_str = f\"[{path}]\\n{statement}\"\n",
    "#                 if nucleus_proximity == \"near\":\n",
    "#                     statements_near.append(statement_str)\n",
    "#                 else:\n",
    "#                     statements_far.append(statement_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(\n",
    "#     \"statements/explanation_elaboration/train/middle_near.txt\", \n",
    "#     \"wt\"\n",
    "# ) as f:\n",
    "#     f.write(\"\\n\".join(statements_near))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(\n",
    "#     \"statements/explanation_elaboration/train/middle_far.txt\", \n",
    "#     \"wt\"\n",
    "# ) as f:\n",
    "#     f.write(\"\\n\".join(statements_far))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
