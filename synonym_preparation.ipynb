{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk.tokenize \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms_df = pd.read_csv(\"synonyms.csv\", skiprows=1, header=None)\n",
    "middle_vocabulary_df = pd.read_csv(\"middle_vocabulary.csv\", usecols=[0, 1])\n",
    "middle_vocabulary_df.columns=[\"word\", \"pos\"]\n",
    "middle_vocabulary = set([w.lower() for w in middle_vocabulary_df.word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word(token):\n",
    "    for c in token:\n",
    "        if not c.isalpha():\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "SynonymList = collections.namedtuple(\n",
    "    \"SynonymList\", [\"word\", \"synonyms\", \"is_original\"]\n",
    ")\n",
    "\n",
    "\n",
    "def extract_synonyms(line, middle_vocabulary, synonym_map):\n",
    "    tokens = [token.lower().strip() for token in nltk.tokenize.word_tokenize(line)]\n",
    "    words = [token for token in tokens if token in middle_vocabulary]\n",
    "    if len(words) >= 2:\n",
    "        synonym_map[words[0]] = SynonymList(words[0], words[1:], True)\n",
    "        for i in range(1, len(words)):\n",
    "            synonyms = words[:i] + words[(i + 1):]\n",
    "            if words[i] not in synonym_map:\n",
    "                synonym_map[words[i]] = SynonymList(\n",
    "                    words[i], synonyms, False\n",
    "                )\n",
    "            else:\n",
    "                if not synonym_map[words[i]].is_original:\n",
    "                    synonym_map[words[i]].synonyms.extend(synonyms)\n",
    "\n",
    "\n",
    "def test__extract_synonyms():\n",
    "    synonym_map = {}\n",
    "    extract_synonyms(\"Blank —– Empty, bare\", {\"blank\", \"empty\"}, synonym_map)\n",
    "    assert synonym_map[\"blank\"].synonyms == [\"empty\"]\n",
    "    assert synonym_map[\"blank\"].is_original == True\n",
    "    assert synonym_map[\"empty\"].synonyms == [\"blank\"]\n",
    "    assert synonym_map[\"empty\"].is_original == False\n",
    "    extract_synonyms(\"Bare —– blank, empty\", {\"blank\", \"empty\", \"bare\"}, synonym_map)\n",
    "    assert synonym_map[\"blank\"].synonyms == [\"empty\"]\n",
    "    assert synonym_map[\"blank\"].is_original == True\n",
    "    assert synonym_map[\"empty\"].synonyms == [\"blank\", \"bare\", \"blank\"]\n",
    "    assert synonym_map[\"empty\"].is_original == False\n",
    "    assert synonym_map[\"bare\"].synonyms == [\"blank\", \"empty\"]\n",
    "    assert synonym_map[\"bare\"].is_original == True\n",
    "\n",
    "    \n",
    "test__extract_synonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_map = {}\n",
    "for _, row in synonyms_df.iterrows():\n",
    "    extract_synonyms(row[0], middle_vocabulary, synonym_map)\n",
    "\n",
    "    \n",
    "result = []\n",
    "for _, synonym_list in sorted(synonym_map.items(), key=lambda item: item[0]):\n",
    "    if synonym_list.is_original:\n",
    "        synonyms = synonym_list.synonyms\n",
    "    else:\n",
    "        synonyms = list(set(synonym_list.synonyms))\n",
    "    result.append(\n",
    "        {\n",
    "            \"word\": synonym_list.word,\n",
    "            \"synonyms\": \", \".join(synonyms),\n",
    "            \"is_original\": synonym_list.is_original\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    result, columns=[\"word\", \"synonyms\", \"is_original\"]\n",
    ").to_csv(\"processed_synonyms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edited_synonyms = pd.read_csv(\"edited_synonyms.csv\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_synonyms[\"is_original\"] = edited_synonyms.word.map(\n",
    "    {w: synonym_list.is_original for w, synonym_list in synonym_map.items()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>is_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>able</td>\n",
       "      <td>capable</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absent</td>\n",
       "      <td>away</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accept</td>\n",
       "      <td>agree, admit</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accident</td>\n",
       "      <td>crash</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>account</td>\n",
       "      <td>consider</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word      synonyms  is_original\n",
       "0      able       capable         True\n",
       "1    absent          away        False\n",
       "2    accept  agree, admit        False\n",
       "3  accident         crash        False\n",
       "4   account      consider        False"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_synonyms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_synonyms_df = pd.read_csv(\"corrected_synonyms.csv\", header=None).dropna()\n",
    "corrected_synonyms_df.columns = [\"word\", \"synonyms\"]\n",
    "corrected_synonyms_df[\"word\"] = corrected_synonyms_df.word.apply(\n",
    "    lambda p: p.strip().strip(\"()\").split(\",\")[0].strip(\"'\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_synonyms = pd.merge(\n",
    "    edited_synonyms,\n",
    "    corrected_synonyms_df,\n",
    "    on=\"word\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_synonyms[\"synonyms\"] = final_synonyms[\"synonyms_x\"]\n",
    "synonyms_y_not_null_mask = ~final_synonyms.synonyms_y.isnull()\n",
    "final_synonyms.loc[synonyms_y_not_null_mask, \"synonyms\"] = final_synonyms.loc[\n",
    "    synonyms_y_not_null_mask, \"synonyms_y\"\n",
    "]\n",
    "final_synonyms.drop([\"synonyms_x\", \"synonyms_y\"], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding Some Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_df = pd.read_csv(\"words_to_exclude.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_exclude = []\n",
    "\n",
    "for i in range(4):\n",
    "    words_to_exclude.extend(\n",
    "        [line.split()[0].lower() for line in exclude_df.loc[~exclude_df[i].isnull(), i]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_synonyms.loc[\n",
    "    final_synonyms.is_original & ~final_synonyms.word.isin(set(words_to_exclude)), \n",
    "    [\"word\", \"synonyms\"]\n",
    "].to_csv(\"filtered_edited_synonyms.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
