{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "from pycorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Constituency = namedtuple(\"Constituency\", [\"tag\", \"startIndex\", \"endIndex\", \"depth\"])\n",
    "\n",
    "\n",
    "def skip_blank_space(parse, pointer):\n",
    "    while pointer < len(parse) and parse[pointer].isspace():\n",
    "        pointer += 1\n",
    "    return pointer\n",
    "\n",
    "\n",
    "def read_tag(parse, pointer):\n",
    "    tag_start = pointer\n",
    "    while pointer < len(parse) and not parse[pointer].isspace():\n",
    "        pointer += 1\n",
    "    return parse[tag_start:pointer], skip_blank_space(parse, pointer)\n",
    "\n",
    "\n",
    "def read_token(parse, pointer, tokens):\n",
    "    token_start = pointer\n",
    "    while pointer < len(parse) and parse[pointer] != \")\":\n",
    "        pointer += 1\n",
    "    tokens.append(parse[token_start:pointer])\n",
    "    return pointer\n",
    "    \n",
    "    \n",
    "def read_body(parse, pointer, constituencies, tokens, depth):\n",
    "    if parse[pointer] == \"(\":\n",
    "        return read_constituency(parse, pointer, constituencies, tokens, depth)\n",
    "    else:\n",
    "        return None, read_token(parse, pointer, tokens)\n",
    "        \n",
    "        \n",
    "def read_constituency(parse, pointer, constituencies, tokens, depth):\n",
    "    assert parse[pointer] == \"(\"\n",
    "    pointer += 1\n",
    "    tag, pointer = read_tag(parse, pointer)\n",
    "    first_child, pointer = read_body(parse, pointer, constituencies, tokens, depth + 1)\n",
    "    if first_child is None:\n",
    "        constituency = Constituency(\n",
    "            tag=tag, startIndex=len(tokens), endIndex=len(tokens) + 1, depth=depth\n",
    "        )\n",
    "        assert parse[pointer] == \")\"\n",
    "    else:\n",
    "        child = first_child\n",
    "        while parse[pointer] != \")\":\n",
    "            child, pointer = read_body(parse, pointer, constituencies, tokens, depth + 1)\n",
    "        constituency = Constituency(\n",
    "            tag=tag, startIndex=first_child.startIndex, endIndex=child.endIndex, depth=depth\n",
    "        )\n",
    "    pointer += 1\n",
    "    constituencies.append(constituency)  \n",
    "    return constituency, skip_blank_space(parse, pointer)\n",
    "\n",
    "\n",
    "def read_constituencies(parse):\n",
    "    constituencies = []\n",
    "    tokens = []\n",
    "    read_constituency(parse, 0, constituencies, tokens, 0)\n",
    "    return constituencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subject(parse):\n",
    "    constituencies = read_constituencies(parse)\n",
    "    np_constituencies = [c for c in constituencies if c.tag == \"NP\"]\n",
    "    if len(np_constituencies) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        top_np_constituency = sorted(np_constituencies, key=lambda c: c.depth)[0]\n",
    "        return top_np_constituency.startIndex, top_np_constituency.endIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_resolution_map(corefs):\n",
    "    resolution_map = {}\n",
    "\n",
    "    for _, coref_group in corefs.items():\n",
    "        representative_mention = None\n",
    "        keys = []\n",
    "        for coref in coref_group:\n",
    "            if coref[\"isRepresentativeMention\"]:\n",
    "                representative_mention = coref[\"text\"]\n",
    "            keys.append((coref[\"sentNum\"], coref[\"startIndex\"], coref[\"endIndex\"]))\n",
    "        for key in keys:\n",
    "            resolution_map[key] = representative_mention    \n",
    "            \n",
    "    return resolution_map\n",
    "\n",
    "\n",
    "def resolve_subject(sentence_num, subject, resolution_map, tokens):\n",
    "    key = (sentence_num, *subject)\n",
    "    if key in resolution_map:\n",
    "        return resolution_map[key]\n",
    "    else:\n",
    "        return \" \".join(\n",
    "            [tokens[index - 1][\"originalText\"] for index in range(*subject)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_resolved_subjects(text, nlp=nlp):\n",
    "    result = nlp.annotate(\n",
    "        text,\n",
    "        properties={\n",
    "           'annotators': 'parse,coref',\n",
    "           'outputFormat': 'json',\n",
    "           'timeout': 60000,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    resolution_map = create_resolution_map(result[\"corefs\"])\n",
    "    \n",
    "    resolved_subjects = []\n",
    "    for i, sent in enumerate(result[\"sentences\"]):\n",
    "        subject = get_subject(sent[\"parse\"])\n",
    "        if subject is None:\n",
    "            resolved_subject = None\n",
    "        else:\n",
    "            resolved_subject = resolve_subject(\n",
    "                i + 1,\n",
    "                subject,\n",
    "                resolution_map,\n",
    "                result[\"sentences\"][i][\"tokens\"]\n",
    "            )\n",
    "        resolved_subjects.append(resolved_subject)\n",
    "    \n",
    "    return resolved_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test__get_resolved_subjects():\n",
    "    text = \"This movie was actually neither that funny, nor super witty. The movie was meh. I liked watching that movie. If I had a choice, I would not watch that movie again.\"\n",
    "    assert get_resolved_subjects(text, nlp) == [\"This movie\", \"This movie\", \"I\", \"I\"]\n",
    "    \n",
    "\n",
    "test__get_resolved_subjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def move_st(text, st, n_prev_sentences):\n",
    "    sent_counter = 0\n",
    "    while st > 0:\n",
    "        if text[st] in {\".\", \"!\", \"?\"}:\n",
    "            sent_counter += 1\n",
    "            if sent_counter > n_prev_sentences:\n",
    "                return st + 1, sent_counter - 1\n",
    "        st -= 1\n",
    "    return 0, sent_counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
