{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import enum\n",
    "import json\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.tokenize\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import aux.defs\n",
    "import aux.relation_extraction\n",
    "import aux.utils\n",
    "import aux.nlp\n",
    "import preparation\n",
    "\n",
    "%run explanation_04.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATEMENTS_DIR = \"/Users/YK/mt/project/statements_3/\"\n",
    "RACE_PART = \"train/middle\"\n",
    "RACE_DIR = \"/Users/YK/mt/RACE\"\n",
    "PARSED_RACE_DIR = \"/Users/YK/mt/parsed/race\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Position(enum.Enum):\n",
    "    BEFORE = \"before\"\n",
    "    NESTED = \"nested\"\n",
    "    AFTER  = \"after\"\n",
    "\n",
    "    \n",
    "Alternative = collections.namedtuple(\n",
    "    \"Alternative\",\n",
    "    [\n",
    "        \"true_statement\", \n",
    "        \"alternative_statement\",\n",
    "        \"relation_type\",\n",
    "        \"position\", \n",
    "        \"distance_words\",\n",
    "        \"distance_sentences\",\n",
    "        \"sn_length\",\n",
    "        \"sn_length_relative_difference\",\n",
    "        \"jaccard_distance\",\n",
    "        \"edit_distance\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_statements(directory, subdirectories, text_no):\n",
    "    statements = {}\n",
    "    for subdirectory in subdirectories:\n",
    "        file_path = os.path.join(\n",
    "            directory, subdirectory, RACE_PART, f\"{text_no}.txt.tree\"\n",
    "        )\n",
    "        if os.path.exists(file_path): \n",
    "            with open(file_path, \"rt\") as f:\n",
    "                statements[subdirectory] = json.load(f)\n",
    "    return statements\n",
    "    \n",
    "\n",
    "def load_relations(text_no, directory):\n",
    "    text, relations, _ = aux.relation_extraction.load_relations(\n",
    "        os.path.join(directory, f\"{text_no}.txt.tree\")\n",
    "    )\n",
    "    return text, relations # {t: relations[t] for t in types if t in relations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements_subdirectories = [\n",
    "    f for f in os.listdir(STATEMENTS_DIR) if os.path.isdir(os.path.join(STATEMENTS_DIR, f))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_n_words(text_span):\n",
    "    return len(nltk.tokenize.word_tokenize(text_span))\n",
    "\n",
    "\n",
    "def get_n_sentences(text_span):\n",
    "    cnt = 0\n",
    "    for c in text_span:\n",
    "        if c in {'.', ',', '!'}:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def get_position_and_distance(statement, relation, text, verbose=False):\n",
    "    if relation.right.end <= statement[\"left_boundary\"]:\n",
    "        span = text[relation.right.end:statement[\"left_boundary\"]]\n",
    "        return (\n",
    "            Position.BEFORE,\n",
    "            get_n_words(span),\n",
    "            get_n_sentences(span)\n",
    "        )\n",
    "    elif relation.left.start >= statement[\"right_boundary\"]:\n",
    "        span = text[statement[\"right_boundary\"]:relation.left.start]\n",
    "        return (\n",
    "            Position.AFTER,\n",
    "            get_n_words(span),\n",
    "            get_n_sentences(span)\n",
    "        )\n",
    "    else:\n",
    "        if (\n",
    "            relation.left.start < statement[\"split_point\"]\n",
    "                and relation.right.end > statement[\"split_point\"]\n",
    "        ):\n",
    "            if verbose:\n",
    "                print(\"The relation overlaps with the relation of the true statement.\")\n",
    "            return None, None, None\n",
    "        else:\n",
    "            if relation.right.end <= statement[\"split_point\"]:\n",
    "                span = text[relation.right.end:statement[\"split_point\"]]\n",
    "                return Position.NESTED, get_n_words(span), get_n_sentences(span)\n",
    "            else:\n",
    "                span = (text[statement[\"split_point\"]:relation.left.start])\n",
    "                return Position.NESTED, get_n_words(span), get_n_sentences(span)\n",
    "\n",
    "    \n",
    "def get_jaccard_distance(phrase_1, phrase_2):\n",
    "    tokens_1 = set(nltk.tokenize.word_tokenize(phrase_1))\n",
    "    tokens_2 = set(nltk.tokenize.word_tokenize(phrase_2))\n",
    "    return nltk.jaccard_distance(tokens_1, tokens_2)\n",
    "\n",
    "\n",
    "def get_edit_distance(phrase_1, phrase_2):\n",
    "    return nltk.edit_distance(phrase_1, phrase_2)\n",
    "    \n",
    "\n",
    "RelationData = collections.namedtuple(\n",
    "    \"RelationData\",\n",
    "    [\"relation\", \"position\", \"distance_words\", \"distance_sentences\"]\n",
    ")\n",
    "\n",
    "\n",
    "def get_k(relation_data_list, closest, k):\n",
    "    sorted_relation_data_list = sorted(\n",
    "        relation_data_list, key=lambda rd: rd.distance_words\n",
    "    )\n",
    "    if closest:\n",
    "        return sorted_relation_data_list[:k]\n",
    "    else:\n",
    "        return sorted_relation_data_list[-k:]\n",
    "        \n",
    "        \n",
    "def filter_relations(statement, relations, text, k=2):\n",
    "    relation_data_lists = collections.defaultdict(list)\n",
    "    for relation in relations:\n",
    "        position, distance_words, distance_sentences = get_position_and_distance(\n",
    "            statement, relation, text\n",
    "        )\n",
    "        if position is not None:\n",
    "            relation_data_lists[position].append(\n",
    "                RelationData(\n",
    "                    relation=relation,\n",
    "                    position=position,\n",
    "                    distance_words=distance_words,\n",
    "                    distance_sentences=distance_sentences\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    result = []\n",
    "    result += get_k(relation_data_lists[Position.BEFORE], closest=True, k=k)\n",
    "    result += get_k(relation_data_lists[Position.AFTER], closest=True, k=k)\n",
    "    result += get_k(relation_data_lists[Position.NESTED], closest=False, k=k)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def create_alternative(statement, relation_data, true_sn_text_len, text, verbose=False):\n",
    "    relation_info = preparation.get_info(relation_data.relation, verbose)\n",
    "    assert relation_info is not None\n",
    "    if relation_info.satellite_info.relation is None:\n",
    "        if verbose:\n",
    "            print(\"Satellite is flat.\")\n",
    "        return None\n",
    "\n",
    "    satellite_handling_result = preparation.Preprocessor.handle_satellite(\n",
    "        text, relation_info.satellite_info, relation_info.nucleus_info.direction, verbose\n",
    "    )\n",
    "    if satellite_handling_result is None:\n",
    "        if verbose:\n",
    "            print(\"Satellite preprocessing was unsuccessful.\")\n",
    "        return None\n",
    "    \n",
    "    processed_sn_text = aux.nlp.take_first_sentence_and_remove_leading_words(\n",
    "        satellite_handling_result.preparation_result.prepared_text, verbose\n",
    "    )\n",
    "    prepared_sn_text = utils.lowercase_first_letter(\n",
    "        processed_sn_text if processed_sn_text is not None \n",
    "            else info.satellite_preparation_result.prepared_text\n",
    "    )\n",
    "    sn_text_len = get_n_words(prepared_sn_text)\n",
    "    \n",
    "    true_statement_nucleus = statement[\"nucleus\"]\n",
    "    connective = statement[\"connective\"]\n",
    "    alternative_text = f\"{true_statement_nucleus}{connective}{prepared_sn_text}\"\n",
    "    return Alternative(\n",
    "        true_statement=statement[\"statement_text\"],\n",
    "        alternative_statement=alternative_text,\n",
    "        position=relation_data.position.value,\n",
    "        relation_type=relation_data.relation.type,\n",
    "        distance_words=relation_data.distance_words,\n",
    "        distance_sentences=relation_data.distance_sentences,\n",
    "        sn_length=sn_text_len,\n",
    "        sn_length_relative_difference=(sn_text_len / true_sn_text_len - 1),\n",
    "        jaccard_distance=get_jaccard_distance(\n",
    "            statement[\"satellite_nucleus\"], prepared_sn_text\n",
    "        ),\n",
    "        edit_distance=get_edit_distance(\n",
    "            statement[\"satellite_nucleus\"], prepared_sn_text\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alternatives(text_no):\n",
    "    rows = []\n",
    "    \n",
    "    text, relation_map = load_relations(\n",
    "        text_no, os.path.join(PARSED_RACE_DIR, RACE_PART)\n",
    "    )\n",
    "    relations = [\n",
    "        relation for _, relations in relation_map.items() for relation in relations\n",
    "    ]\n",
    "    statement_map = load_statements(STATEMENTS_DIR, statements_subdirectories, text_no)\n",
    "    for _, statements in statement_map.items():\n",
    "        for statement in statements:\n",
    "            true_sn_text_len = get_n_words(statement[\"satellite_nucleus\"])\n",
    "            filtered_relation_data = filter_relations(statement, relations, text)\n",
    "            for relation_data in filtered_relation_data:\n",
    "                alternative = create_alternative(\n",
    "                    statement, relation_data, true_sn_text_len, text\n",
    "                )\n",
    "                if alternative is not None:\n",
    "                    row_dict = alternative._asdict()\n",
    "                    row_dict.update(\n",
    "                        {\n",
    "                            \"text_no\": text_no,\n",
    "                            \"rule\": statement[\"rule\"],\n",
    "                            \"reason\": statement[\"reason\"][1]\n",
    "                        }\n",
    "                    )\n",
    "                    rows.append(\n",
    "                        row_dict\n",
    "                    )\n",
    "    return rows\n",
    "\n",
    "\n",
    "def create_df(rows):\n",
    "    if len(rows) > 0:\n",
    "        result_df = pd.DataFrame(rows)[\n",
    "            [\n",
    "                \"text_no\",\n",
    "                \"true_statement\", \n",
    "                \"alternative_statement\",\n",
    "                \"relation_type\",\n",
    "                \"position\",        \n",
    "                \"distance_words\",\n",
    "                \"distance_sentences\",\n",
    "                \"sn_length\",\n",
    "                \"sn_length_relative_difference\",\n",
    "                \"jaccard_distance\",\n",
    "                \"edit_distance\",\n",
    "                \"rule\",\n",
    "                \"reason\"\n",
    "            ]\n",
    "        ]\n",
    "        result_df[\"d\"] = (\n",
    "            result_df.distance_words \n",
    "                * (1 - 2 * (result_df.position == Position.NESTED).astype(int))\n",
    "        )\n",
    "        result_df.sort_values(\n",
    "            [\"text_no\", \"rule\", \"true_statement\", \"position\", \"d\"], inplace=True\n",
    "        )\n",
    "        result_df.drop(\"d\", 1, inplace=True)\n",
    "\n",
    "        return result_df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_numbers = [\n",
    "    int(fn.split('.')[0]) for fn in os.listdir(os.path.join(RACE_DIR, RACE_PART))\n",
    "        if fn[-4:] == \".txt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for text_no in text_numbers[:50]:\n",
    "    rows.extend(generate_alternatives(text_no))\n",
    "\n",
    "result_df = create_df(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df.to_excel(\n",
    "    os.path.join(\n",
    "        STATEMENTS_DIR, \n",
    "        f\"alternatives_{RACE_PART.replace('/', '-')}_{random.randint(0, 2**32):x}.xlsx\"\n",
    "    ),\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
