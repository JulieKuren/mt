{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /Users/YK/mt/project/aux/utils.ipynb\n",
      "importing Jupyter notebook from /Users/YK/mt/project/aux/nlp.ipynb\n",
      "importing Jupyter notebook from /Users/YK/mt/project/aux/relation_extraction.ipynb\n",
      "importing Jupyter notebook from /Users/YK/mt/project/aux/defs.ipynb\n",
      "importing Jupyter notebook from preparation.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from aux import utils\n",
    "from aux import nlp\n",
    "from aux import relation_extraction\n",
    "from aux import defs\n",
    "import preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleTopicComment01(defs.Rule):\n",
    "    name = \"topic_comment_01\"\n",
    "    relation_type = \"Topic-Comment\"\n",
    "    reasons = {\n",
    "        \"S_HAS_WH_WORD_AND_?\": \n",
    "            defs.Reason(\n",
    "                1,\n",
    "                \"The satellite starts with a wh-word and ends with '?'.\"\n",
    "            ),\n",
    "        \"QUESTION_IN_MAIN_N\": \n",
    "            defs.Reason(\n",
    "                2,\n",
    "                \"There is a question in the main nucleus\"\n",
    "            )\n",
    "    }\n",
    "\n",
    "    def get_first_question(text):\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        st = 0\n",
    "        while st < len(tokens):\n",
    "            if tokens[st].lower() in preparation.wh_words:\n",
    "                end = st + 1\n",
    "                while end < len(tokens):\n",
    "                    if tokens[end] == '?':\n",
    "                        return \" \".join(tokens[st:end]) + \"?\"\n",
    "                    elif tokens[end] in {\".\", \"!\"}:\n",
    "                        st = end\n",
    "                        break\n",
    "                    end += 1\n",
    "            st += 1\n",
    "        return None\n",
    "    \n",
    "    def get_first_sentence_with_question(text):\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        wh_words = set(preparation.wh_words)\n",
    "        for sentence in sentences:\n",
    "            sent_tokens = set([t.lower() for t in nltk.word_tokenize(sentence)])\n",
    "            if len(wh_words.intersection(sent_tokens)) > 0 and \"?\" in sent_tokens:\n",
    "                return utils.fix_spacing(sentence[:(sentence.index(\"?\") + 1)])\n",
    "        return None\n",
    "\n",
    "    def generate_statement(self, text, relation, main_nucleus_text, verbose=False):\n",
    "        assert(relation is not None and relation.type == \"Topic-Comment\")\n",
    "        info = preparation.Preprocessor.prepare_extended_info(text, relation, verbose)\n",
    "        if info is None:\n",
    "            utils.print_if_verbose(\"Extended info preparation wasn't successful.\", verbose)\n",
    "            return None\n",
    "\n",
    "        reason = None\n",
    "        \n",
    "        cleaned_s = preparation.clean(\n",
    "            text[info.satellite_info.segment.start:info.satellite_info.segment.end]\n",
    "        )\n",
    "        s_tokens = utils.lowercase_and_tokenize(\n",
    "            cleaned_s\n",
    "        )\n",
    "        if (\n",
    "            len(s_tokens) >= 2 \n",
    "                and s_tokens[0] in preparation.wh_words \n",
    "                and s_tokens[-1] == '?'\n",
    "        ):\n",
    "            reason = self.reasons[\"S_HAS_WH_WORD_AND_?\"]\n",
    "            statement_text = cleaned_s\n",
    "        else:\n",
    "            statement_text = RuleTopicComment01.get_first_sentence_with_question(\n",
    "                main_nucleus_text\n",
    "            )\n",
    "            if statement_text is not None:\n",
    "                reason = self.reasons[\"QUESTION_IN_MAIN_N\"]\n",
    "\n",
    "        if reason is not None:\n",
    "            utils.print_if_verbose(reason.explanation, verbose)\n",
    "            \n",
    "            return defs.Statement(\n",
    "                    statement_text=statement_text,\n",
    "                    nucleus=None,\n",
    "                    satellite_nucleus=None,\n",
    "                    left_boundary=None,\n",
    "                    right_boundary=None,\n",
    "                    nucleus_proximity=None,\n",
    "                    rule=self.name,\n",
    "                    reason=reason\n",
    "                )\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        \n",
    "def test__RuleTopicComment01_get_first_question():\n",
    "    assert (\n",
    "        RuleTopicComment01.get_first_question(\n",
    "            \"Why! Bla-bla-bla. What is your favourite colour? bla\"\n",
    "        ) == \"What is your favourite colour?\"\n",
    "    )\n",
    "    \n",
    "    assert (\n",
    "        RuleTopicComment01.get_first_question(\n",
    "            \"Why ? Bla-bla-bla. What is your favourite colour? bla\"\n",
    "        ) == \"Why?\"        \n",
    "    )\n",
    "    \n",
    "    assert (\n",
    "        RuleTopicComment01.get_first_question(\n",
    "            \"Why ! Bla-bla-bla. What is your favourite colour. bla\"\n",
    "        ) is None        \n",
    "    )\n",
    "    \n",
    "    \n",
    "def test__RuleTopicComment01_get_first_sentence_with_question():\n",
    "    assert (\n",
    "        RuleTopicComment01.get_first_sentence_with_question(\n",
    "            \"Bla-bla-bla. Tell me what your favourite colour is! bla\"\n",
    "        ) == None\n",
    "    )\n",
    "    \n",
    "    assert (\n",
    "        RuleTopicComment01.get_first_sentence_with_question(\n",
    "            \"Bla-bla-bla. What is your favourite colour? bla\"\n",
    "        ) == \"What is your favourite colour?\"        \n",
    "    )\n",
    "    \n",
    "    assert (\n",
    "        RuleTopicComment01.get_first_sentence_with_question(\n",
    "            \"Bla-bla-bla. Yellow is her favourite colour. bla\"\n",
    "        ) is None        \n",
    "    )\n",
    "    \n",
    "    assert (\n",
    "        RuleTopicComment01.get_first_sentence_with_question(\n",
    "            \"Bla-bla-bla. Yellow is her favourite colour. bla\"\n",
    "        ) is None        \n",
    "    )\n",
    "    \n",
    "    \n",
    "test__RuleTopicComment01_get_first_question()\n",
    "test__RuleTopicComment01_get_first_sentence_with_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have you ever heard of e-waste ( electronic waste , ) , which can be produced every day ?  How do you deal with your computers , MP4 players and mobile phones when they 're broken or you want a new one ?  \n",
      "Nucleus is on the left.\n",
      "Nucleus's depth <= 3.\n",
      "Parsing result:\n",
      "(ROOT\n",
      "  (SQ (VBP Have)\n",
      "    (NP\n",
      "      (NP (PRP you))\n",
      "      (SBAR\n",
      "        (S\n",
      "          (VP\n",
      "            (ADVP (RB ever))\n",
      "            (VBD heard)\n",
      "            (PP (IN of)\n",
      "              (NP\n",
      "                (NP\n",
      "                  (NP (NN e-waste))\n",
      "                  (PRN (-LRB- -LRB-)\n",
      "                    (ADVP (JJ electronic))\n",
      "                    (NP (NN waste))\n",
      "                    (, ,))\n",
      "                  (-RRB- -RRB-))\n",
      "                (, ,)\n",
      "                (SBAR\n",
      "                  (WHNP (WDT which))\n",
      "                  (S\n",
      "                    (VP (MD can)\n",
      "                      (VP (VB be)))))))))))\n",
      "    (VP (VBN produced)\n",
      "      (NP-TMP (DT every) (NN day)))\n",
      "    (. ?)))\n",
      "\n",
      "Constituencies:\n",
      "      type  start  end  depth\n",
      "0      VBP      0    1      2\n",
      "1      PRP      1    2      4\n",
      "2       NP      1    2      3\n",
      "3       RB      2    3      7\n",
      "4     ADVP      2    3      6\n",
      "5      VBD      3    4      6\n",
      "6       IN      4    5      7\n",
      "7       NN      5    6     10\n",
      "8       NP      5    6      9\n",
      "9    -LRB-      6    7     10\n",
      "10      JJ      7    8     11\n",
      "11    ADVP      7    8     10\n",
      "12      NN      8    9     11\n",
      "13      NP      8    9     10\n",
      "14       ,      9   10     10\n",
      "15     PRN      6   10      9\n",
      "16   -RRB-     10   11      9\n",
      "17      NP      5   11      8\n",
      "18       ,     11   12      8\n",
      "19     WDT     12   13     10\n",
      "20    WHNP     12   13      9\n",
      "21      MD     13   14     11\n",
      "22      VB     14   15     12\n",
      "23      VP     14   15     11\n",
      "24      VP     13   15     10\n",
      "25       S     13   15      9\n",
      "26    SBAR     12   15      8\n",
      "27      NP      5   15      7\n",
      "28      PP      4   15      6\n",
      "29      VP      2   15      5\n",
      "30       S      2   15      4\n",
      "31    SBAR      2   15      3\n",
      "32      NP      1   15      2\n",
      "33     VBN     15   16      3\n",
      "34      DT     16   17      4\n",
      "35      NN     17   18      4\n",
      "36  NP-TMP     16   18      3\n",
      "37      VP     15   18      2\n",
      "38       .     18   19      2\n",
      "39      SQ      0   19      1\n",
      "40    ROOT      0   19      0\n",
      "\n",
      "Sentence starts at 0.\n",
      "Boundaries: (0, 6, 6, 19)\n",
      "Didn't find the left VP.\n",
      "Nucleus's (left) nucleus doesn't contain '.', '!', '?', or ';' but none of the other two conditions is met.\n",
      "Will use the whole segment.\n",
      "Satellite's nucleus is on the left.\n",
      "Nuclei proximity is NucleusProximity.NEAR\n",
      "Satellite's right subsegment starts with a wh-word or 'how'.\n",
      "Satellite's (left) nucleus doesn't contain '.', '!', '?', or ';' but none of the other two conditions is met.\n",
      "Will use the whole segment.\n",
      "Text extracted from the satellite:\n",
      "How do you deal with your computers, MP4 players and mobile phones when they're broken or you want a new one?\n",
      "The satellite starts with a wh-word and ends with '?'.\n",
      "\n",
      "RESULT:\n",
      "{\n",
      "  \"statement_text\": \"How do you deal with your computers, MP4 players and mobile phones when they're broken or you want a new one?\",\n",
      "  \"nucleus\": null,\n",
      "  \"satellite_nucleus\": null,\n",
      "  \"left_boundary\": null,\n",
      "  \"right_boundary\": null,\n",
      "  \"nucleus_proximity\": null,\n",
      "  \"rule\": \"topic_comment_01\",\n",
      "  \"reason\": [\n",
      "    1,\n",
      "    \"The satellite starts with a wh-word and ends with '?'.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" and \"__file__\" not in globals():\n",
    "    rule = RuleTopicComment01()\n",
    "\n",
    "    with open(\"../parsed/race/train/middle/6121.txt.tree\", \"rt\") as f:\n",
    "        tree_text = f.read()\n",
    "    \n",
    "    cleaned_tree_text = tree_text.replace(\"<s>\", \"\").replace(\"<P>\", \"\")\n",
    "    \n",
    "    text, relations = relation_extraction.read_relations(\n",
    "        cleaned_tree_text\n",
    "    )\n",
    "    \n",
    "    root = relation_extraction.read_relation_tree(cleaned_tree_text)\n",
    "    assert root is not None\n",
    "    _, main_nucleus_segment = root.get_first_nucleus()\n",
    "    main_nucleus_text = text[\n",
    "        main_nucleus_segment.start:main_nucleus_segment.end\n",
    "    ]\n",
    "    \n",
    "    tc = relations[\"Topic-Comment\"][0]\n",
    "    print(text[tc.left.start:tc.right.end])\n",
    "    \n",
    "    statement =rule.generate_statement(text, tc, main_nucleus_text, verbose=True)\n",
    "    print(\"\\nRESULT:\")\n",
    "    if statement is not None:\n",
    "        print(json.dumps(statement._asdict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you put together one group of sheep and another group of sheep , how many groups of sheep do you have ? \"  \" Why !  That 's an easy question .  \n",
      "Nucleus is on the left.\n",
      "Nucleus's depth <= 3.\n",
      "Nucleus's left subsegment is not nucleus.\n",
      "Will use the whole segment.\n",
      "Satellite's nucleus is on the left.\n",
      "Nuclei proximity is NucleusProximity.NEAR\n",
      "Satellite's (left) nucleus contains '.', '!', '?', or ';'.\n",
      "Will use the whole segment.\n",
      "Text extracted from the satellite:\n",
      "\" Why!  That's an easy question.\n",
      "There is a question in the main nucleus\n",
      "\n",
      "RESULT:\n",
      "{\n",
      "  \"statement_text\": \"Can you tell me why you are so clever?\",\n",
      "  \"nucleus\": null,\n",
      "  \"satellite_nucleus\": null,\n",
      "  \"left_boundary\": null,\n",
      "  \"right_boundary\": null,\n",
      "  \"nucleus_proximity\": null,\n",
      "  \"rule\": \"topic_comment_01\",\n",
      "  \"reason\": [\n",
      "    2,\n",
      "    \"There is a question in the main nucleus\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" and \"__file__\" not in globals():\n",
    "    rule = RuleTopicComment01()\n",
    "\n",
    "    with open(\"../parsed/race/train/middle/6814.txt.tree\", \"rt\") as f:\n",
    "        tree_text = f.read()\n",
    "    \n",
    "    cleaned_tree_text = tree_text.replace(\"<s>\", \"\").replace(\"<P>\", \"\")\n",
    "    \n",
    "    text, relations = relation_extraction.read_relations(\n",
    "        cleaned_tree_text\n",
    "    )\n",
    "    \n",
    "    root = relation_extraction.read_relation_tree(cleaned_tree_text)\n",
    "    assert root is not None\n",
    "    _, main_nucleus_segment = root.get_first_nucleus()\n",
    "    main_nucleus_text = text[\n",
    "        main_nucleus_segment.start:main_nucleus_segment.end\n",
    "    ]\n",
    "    \n",
    "    tc = relations[\"Topic-Comment\"][0]\n",
    "    print(text[tc.left.start:tc.right.end])\n",
    "    \n",
    "    statement =rule.generate_statement(text, tc, main_nucleus_text, verbose=True)\n",
    "    print(\"\\nRESULT:\")\n",
    "    if statement is not None:\n",
    "        print(json.dumps(statement._asdict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
