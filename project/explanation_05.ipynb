{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from aux import utils\n",
    "from aux import nlp\n",
    "from aux import relation_extraction\n",
    "from aux import defs\n",
    "import preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RuleExplanation05(defs.Rule):\n",
    "    name = \"explanation_05\"\n",
    "    relation_type = \"Explanation\"\n",
    "    reasons = {\n",
    "        \"COMMON_PATTERN_-_EXPLANATION->CONDITION\": \n",
    "            defs.Reason(\n",
    "                1,\n",
    "                \"Common pattern ( -Explanation->Condition).\"\n",
    "            ),\n",
    "        \"COMMON_PATTERN_CONDITION-EXPLANATION\": \n",
    "            defs.Reason(\n",
    "                2,\n",
    "                \"Common pattern (Condition-Explanation).\"\n",
    "            ),\n",
    "        \"COMMON_PATTERN_WHATEVER-CONTRAST\": \n",
    "            defs.Reason(\n",
    "                3,\n",
    "                \"Common pattern ( -Contrast).\"\n",
    "            )\n",
    "    }\n",
    "    \n",
    "    def generate_statement(self, text, relation, verbose=False):\n",
    "        assert(relation is not None and relation.type == \"Explanation\")\n",
    "        info = preparation.Preprocessor.prepare_extended_info(text, relation, verbose)\n",
    "        if info is None:\n",
    "            utils.print_if_verbose(\"Extended info preparation wasn't successful.\", verbose)\n",
    "            return None\n",
    "        \n",
    "        utils.print_if_verbose(\n",
    "                \"Nucleus relation type: \"\n",
    "                f\"'{utils.get_relation_type(info.nucleus_info.relation)}'.\",\n",
    "                verbose\n",
    "            )\n",
    "        utils.print_if_verbose(\n",
    "            \"Satellite relation type: \"\n",
    "            f\"'{utils.get_relation_type(info.satellite_info.relation)}'.\",\n",
    "            verbose\n",
    "        )\n",
    "            \n",
    "        reason = None\n",
    "        \n",
    "        assert info.satellite_info.relation.type is not None\n",
    "        if info.nucleus_info.relation is None:\n",
    "            if (\n",
    "                info.satellite_info.relation.type == \"Explanation\"\n",
    "                    and info.sn_relation is not None\n",
    "                    and info.sn_relation.type == \"Condition\"\n",
    "            ):\n",
    "                reason = self.reasons[\"COMMON_PATTERN_-_EXPLANATION->CONDITION\"]\n",
    "        else:\n",
    "            if (\n",
    "                info.nucleus_info.relation.type == \"Condition\"\n",
    "                    and info.satellite_info.relation.type == \"Explanation\"\n",
    "            ):\n",
    "                reason = self.reasons[\"COMMON_PATTERN_CONDITION_EXPLANATION\"]\n",
    "            elif info.satellite_info.relation.type == \"Contrast\":\n",
    "                reason = self.reasons[\"COMMON_PATTERN_-_CONTRAST\"]\n",
    "\n",
    "        if reason is not None:\n",
    "            utils.print_if_verbose(reason.explanation, verbose)\n",
    "            \n",
    "            prepared_nucleus_text = utils.remove_trailing_punctuation(\n",
    "                utils.uppercase_first_letter(info.nucleus_preparation_result.prepared_text)\n",
    "            )\n",
    "            processed_sn_text = nlp.remove_leading_words(\n",
    "                info.satellite_preparation_result.prepared_text, verbose\n",
    "            )\n",
    "            prepared_sn_text = utils.lowercase_first_letter(\n",
    "                processed_sn_text if processed_sn_text is not None \n",
    "                    else info.sn_text\n",
    "            )\n",
    "            statement_text = f\"{prepared_nucleus_text} but {prepared_sn_text}\"\n",
    "            return defs.Statement(\n",
    "                statement_text=statement_text,\n",
    "                nucleus=prepared_nucleus_text,\n",
    "                satellite_nucleus=prepared_sn_text,\n",
    "                left_boundary=relation.left.start,\n",
    "                right_boundary=relation.right.end,\n",
    "                nucleus_proximity=info.nucleus_proximity.value,\n",
    "                rule=self.name,\n",
    "                reason=reason\n",
    "            )\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typhoons are very dangerous .  In 2004 , Typhoon Yunna killed 164 people in Zhejiang , and 24 people were missing .  \n",
      "Nucleus is on the left.\n",
      "Nucleus's depth <= 3.\n",
      "Nucleus is flat.\n",
      "Will use the whole segment.\n",
      "Satellite's nucleus is on the left.\n",
      "Nuclei proximity is NucleusProximity.NEAR\n",
      "The depth of the satellite's nucleus <= 3.\n",
      "Parsing result:\n",
      "(ROOT\n",
      "  (S\n",
      "    (PP (IN In)\n",
      "      (NP (CD 2004)))\n",
      "    (, ,)\n",
      "    (S\n",
      "      (NP (NNP Typhoon) (NNP Yunna))\n",
      "      (VP (VBD killed)\n",
      "        (NP (CD 164) (NNS people))\n",
      "        (PP (IN in)\n",
      "          (NP (NNP Zhejiang)))))\n",
      "    (, ,)\n",
      "    (CC and)\n",
      "    (S\n",
      "      (NP (CD 24) (NNS people))\n",
      "      (VP (VBD were)\n",
      "        (ADJP (VBG missing))))\n",
      "    (. .)))\n",
      "\n",
      "Constituencies:\n",
      "    type  start  end  depth\n",
      "0     IN      0    1      3\n",
      "1     CD      1    2      4\n",
      "2     NP      1    2      3\n",
      "3     PP      0    2      2\n",
      "4      ,      2    3      2\n",
      "5    NNP      3    4      4\n",
      "6    NNP      4    5      4\n",
      "7     NP      3    5      3\n",
      "8    VBD      5    6      4\n",
      "9     CD      6    7      5\n",
      "10   NNS      7    8      5\n",
      "11    NP      6    8      4\n",
      "12    IN      8    9      5\n",
      "13   NNP      9   10      6\n",
      "14    NP      9   10      5\n",
      "15    PP      8   10      4\n",
      "16    VP      5   10      3\n",
      "17     S      3   10      2\n",
      "18     ,     10   11      2\n",
      "19    CC     11   12      2\n",
      "20    CD     12   13      4\n",
      "21   NNS     13   14      4\n",
      "22    NP     12   14      3\n",
      "23   VBD     14   15      4\n",
      "24   VBG     15   16      5\n",
      "25  ADJP     15   16      4\n",
      "26    VP     14   16      3\n",
      "27     S     12   16      2\n",
      "28     .     16   17      2\n",
      "29     S      0   17      1\n",
      "30  ROOT      0   17      0\n",
      "\n",
      "Sentence starts at 950.\n",
      "Boundaries: (0, 11, 11, 17)\n",
      "Left and right VP boundaries: (5, 10), (14, 16)\n",
      "Umbrella VPs:\n",
      "Empty DataFrame\n",
      "Columns: [type, start, end, depth]\n",
      "Index: []\n",
      "Satellite's (left) nucleus doesn't contain '.', '!', '?', or ';' but none of the other two conditions is met.\n",
      "Will use the whole segment.\n",
      "Nucleus relation type: '-'.\n",
      "Satellite relation type: 'Joint'.\n",
      "\n",
      "RESULT:\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" and \"__file__\" not in globals():\n",
    "    rule = RuleExplanation05()\n",
    "\n",
    "    with open(\"../parsed/race/train/middle/1310.txt.tree\", \"rt\") as f:\n",
    "        tree_text = f.read()\n",
    "\n",
    "    text, relations = relation_extraction.read_relations(\n",
    "        tree_text.replace(\"<s>\", \"\").replace(\"<P>\", \"\")\n",
    "    )\n",
    "\n",
    "    expl = relations[\"Explanation\"][0]\n",
    "    print(text[expl.left.start:expl.right.end])\n",
    "\n",
    "    statement =rule.generate_statement(text, expl, verbose=True)\n",
    "    print(\"\\nRESULT:\")\n",
    "    if statement is not None:\n",
    "        print(json.dumps(statement._asdict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
