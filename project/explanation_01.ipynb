{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /Users/YK/mt/project/aux/utils.ipynb\n",
      "importing Jupyter notebook from /Users/YK/mt/project/aux/nlp.ipynb\n",
      "importing Jupyter notebook from /Users/YK/mt/project/aux/relation_extraction.ipynb\n",
      "importing Jupyter notebook from /Users/YK/mt/project/aux/defs.ipynb\n",
      "importing Jupyter notebook from preparation.ipynb\n",
      "importing Jupyter notebook from rule_base.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from aux import utils\n",
    "from aux import nlp\n",
    "from aux import relation_extraction\n",
    "from aux import defs\n",
    "import preparation\n",
    "import rule_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_subjects_differ(text, rel, n_prev_sent=5):\n",
    "    new_st, left_segment_sent_no = nlp.move_st(\n",
    "        text, rel.left.start, n_prev_sent\n",
    "    )\n",
    "    if len({\".\", \"!\", \"?\"}.intersection(\n",
    "        set(word_tokenize(text[rel.left.start:rel.right.end])))) > 0:\n",
    "        right_segment_sent_no = left_segment_sent_no + 1\n",
    "    else:\n",
    "        right_segment_sent_no = left_segment_sent_no\n",
    "\n",
    "    if left_segment_sent_no == right_segment_sent_no:\n",
    "        return True\n",
    "    else:\n",
    "        resolved_subjects = nlp.get_resolved_subjects(text[new_st:rel.right.end])\n",
    "        if len(resolved_subjects) < right_segment_sent_no:\n",
    "            return True\n",
    "        else:\n",
    "            return (\n",
    "                resolved_subjects[left_segment_sent_no] \n",
    "                != resolved_subjects[right_segment_sent_no]\n",
    "            )\n",
    "\n",
    "        \n",
    "def test__do_subjects_differ():\n",
    "    text = \"\"\"Nika lives in Berlin. She goes to a Kita. Her favourite color is yellow.\"\"\"\n",
    "    assert do_subjects_differ(\n",
    "        text, \n",
    "        relation_extraction.Relation(\n",
    "            \"\", \n",
    "            relation_extraction.Segment(\"N\", 22, 42), \n",
    "            relation_extraction.Segment(\"S\", 42, len(text)), \n",
    "            None, \n",
    "            None\n",
    "        )\n",
    "    )\n",
    "    text = \"\"\"Nika lives in Berlin. She goes to a Kita. She likes yellow things.\"\"\"\n",
    "    assert not do_subjects_differ(\n",
    "        text, \n",
    "        relation_extraction.Relation(\n",
    "            \"\", \n",
    "            relation_extraction.Segment(\"N\", 22, 42), \n",
    "            relation_extraction.Segment(\"S\", 42, len(text)), \n",
    "            None, \n",
    "            None\n",
    "        )\n",
    "    )    \n",
    "\n",
    "    \n",
    "test__do_subjects_differ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ItMakesParseResult = collections.namedtuple(\n",
    "    \"ItMakesParseResult\", [\"success\", \"subject\", \"verb\", \"rest\"]\n",
    ")\n",
    "\n",
    "\n",
    "def safe_access(tokens, i):\n",
    "    if i < len(tokens):\n",
    "        return tokens[i]\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "def normalise_and_identify_person(subject):\n",
    "    subject = subject.lower()\n",
    "    if subject == \"me\":\n",
    "        return \"I\", 1\n",
    "    elif subject == \"us\":\n",
    "        return \"we\", 1\n",
    "    elif subject == \"you\":\n",
    "        return \"you\", 2\n",
    "    elif subject == \"him\":\n",
    "        return \"he\", 3\n",
    "    elif subject == \"her\":\n",
    "        return \"she\", 3\n",
    "    elif subject == \"them\":\n",
    "        return \"they\", 3\n",
    "    else:\n",
    "        return subject, 3\n",
    "    \n",
    "    \n",
    "def parse_it_makes(tokens, verbose=False):\n",
    "    if safe_access(tokens, 0).lower() == \"it\":\n",
    "        make_pos = -1\n",
    "        \n",
    "        if nlp.normalise_verb(safe_access(tokens, 1).lower()) == \"make\": #it makes ...\n",
    "            make_pos = 1\n",
    "        elif nlp.normalise_verb(safe_access(tokens, 2).lower()) == \"make\": #it is making ...\n",
    "            make_pos = 2\n",
    "        if make_pos < 0:\n",
    "            utils.print_if_verbose(\"Didn't find 'make'.\", verbose)\n",
    "            return ItMakesParseResult(False, None, None, None)\n",
    "        else:\n",
    "            first_verb_position = nlp.find_first_verb(\" \".join(tokens[make_pos + 1:]))\n",
    "            if first_verb_position is None:\n",
    "                utils.print_if_verbose(\n",
    "                    \"Didn't find the verb. Will look for an adjective.\", verbose\n",
    "                ) #It makes me sad.\n",
    "                first_adj_position = nlp.find_first_adjective(\" \".join(tokens[make_pos + 1:]))\n",
    "                if first_adj_position is None:\n",
    "                    utils.print_if_verbose(\"Didn't find an adjective either.\")\n",
    "                    return ItMakesParseResult(False, None, None, None)\n",
    "                else:\n",
    "                    verb = \"be\" #I am sad\n",
    "                    subject = \" \".join(\n",
    "                        tokens[make_pos + 1:(make_pos + 1 + first_adj_position)]\n",
    "                    )\n",
    "                    rest = \" \".join(tokens[(make_pos + 1 + first_adj_position):])\n",
    "            else:\n",
    "                verb = tokens[make_pos + 1 + first_verb_position]\n",
    "                subject = \" \".join(\n",
    "                    tokens[make_pos + 1:(make_pos + 1 + first_verb_position)]\n",
    "                )\n",
    "                rest = \" \".join(tokens[(make_pos + 1 + first_verb_position + 1):])\n",
    "            \n",
    "            if tokens[make_pos] in {\"make\", \"makes\", \"making\"}:\n",
    "                tense = nlp.Tense.PRESENT\n",
    "            elif tokens[make_pos] == \"made\":\n",
    "                tense = nlp.Tense.PAST\n",
    "            else:\n",
    "                assert False\n",
    "            normalised_subject, person = normalise_and_identify_person(subject)\n",
    "            if nlp.is_plural(normalised_subject):\n",
    "                number = nlp.Number.PLURAL\n",
    "            else:\n",
    "                number = nlp.Number.SINGULAR\n",
    "            return ItMakesParseResult(\n",
    "                True, \n",
    "                normalised_subject, \n",
    "                nlp.conjugate(verb, tense, person, number),\n",
    "                rest\n",
    "            )\n",
    "    else:\n",
    "        return ItMakesParseResult(False, None, None, None)\n",
    "\n",
    "        \n",
    "def check_parse_result(parse_result, true_subject, true_verb):\n",
    "    return parse_result.subject == true_subject and parse_result.verb == true_verb\n",
    "\n",
    "\n",
    "def test__parse_it_makes():\n",
    "    parse_result = parse_it_makes(\n",
    "        utils.lowercase_and_tokenize(\"It's making him feel happy.\")\n",
    "    )\n",
    "    check_parse_result(parse_result, \"he\", \"feels\")\n",
    "\n",
    "    parse_result = parse_it_makes(\n",
    "        utils.lowercase_and_tokenize(\"It makes them feel happy.\")\n",
    "    )\n",
    "    check_parse_result(parse_result, \"they\", \"feel\")\n",
    "\n",
    "    parse_result = parse_it_makes(\n",
    "        utils.lowercase_and_tokenize(\"It makes the cats happy.\")\n",
    "    )\n",
    "    check_parse_result(parse_result, \"the cats\", \"are\")\n",
    "\n",
    "    parse_result = parse_it_makes(\n",
    "        utils.lowercase_and_tokenize(\"It makes the cat happy.\")\n",
    "    )\n",
    "    check_parse_result(parse_result, \"the cat\", \"is\")\n",
    "\n",
    "    parse_result = parse_it_makes(\n",
    "        utils.lowercase_and_tokenize(\"It has made the cat happy.\")\n",
    "    )\n",
    "    check_parse_result(parse_result, \"the cat\", \"was\")\n",
    "\n",
    "    parse_result = parse_it_makes(\n",
    "        utils.lowercase_and_tokenize(\"It has made the cats happy.\")\n",
    "    )\n",
    "    check_parse_result(parse_result, \"the cat\", \"were\")\n",
    "\n",
    "    parse_result = parse_it_makes(\n",
    "        utils.lowercase_and_tokenize(\"It has made the cats go home.\")\n",
    "    )\n",
    "    check_parse_result(parse_result, \"the cats\", \"went\")\n",
    "    \n",
    "    parse_result = parse_it_makes(\n",
    "        utils.lowercase_and_tokenize(\"It has made Mr. Smith go home.\")\n",
    "    )\n",
    "    check_parse_result(parse_result, \"Mr. Smith\", \"went\")\n",
    "\n",
    "    \n",
    "test__parse_it_makes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RuleExplanation01(rule_base.Rule):\n",
    "    name = \"explanation_01\"\n",
    "    relation_type = \"Explanation\"\n",
    "    reasons = {\n",
    "        \"N_STARTS_WITH_BUT\": \n",
    "            defs.Reason(1, \"Nucleus starts with 'but'.\"),\n",
    "        \"N_STARTS_WITH_IF\": \n",
    "            defs.Reason(\n",
    "                2, \n",
    "                \"Nucleus starts with 'if' and its left subrelation is not 'Condition'.\"\n",
    "            ),\n",
    "        \"N_CONTAINS_BECAUSE\": \n",
    "            defs.Reason(\n",
    "                3, \n",
    "                \"Nucleus contains 'because'.\"\n",
    "            ),\n",
    "        \"SN_STARTS_WITH_BUT\": \n",
    "            defs.Reason(4, \"Satellite's nucleus starts with 'but'.\"),\n",
    "        \"SN_CONTAINS_BECAUSE\": \n",
    "            defs.Reason(\n",
    "                5, \n",
    "                \"Satellite's nucleus contains 'because'.\"\n",
    "            ),\n",
    "        \"SN_STARTS_WITH_IT_MAKES\":\n",
    "            defs.Reason(\n",
    "                6,\n",
    "                \"Satellite's nucleus starts with 'It makes/made'.\"\n",
    "            )\n",
    "    }\n",
    "    \n",
    "    def generate_statement(self, text, relation, verbose=False, **kwargs):\n",
    "        assert(relation is not None and relation.type == \"Explanation\")\n",
    "        info = preparation.Preprocessor.prepare_extended_info(\n",
    "            text, relation, verbose\n",
    "        ) # finding N,S and the nested ones\n",
    "        if info is None:\n",
    "            utils.print_if_verbose(\"Extended info preparation wasn't successful.\", verbose)\n",
    "            return None\n",
    "        \n",
    "        if info.satellite_info.relation is None:\n",
    "            return None\n",
    "        \n",
    "        nucleus_tokens = utils.lowercase_and_tokenize(\n",
    "            info.nucleus_preparation_result.prepared_text\n",
    "        )\n",
    "        assert len(nucleus_tokens) > 0\n",
    "        utils.print_if_verbose(\n",
    "            \"Satellite's nucleus text: \\n\"\n",
    "            f\"{info.satellite_preparation_result.prepared_text}\", \n",
    "            verbose\n",
    "        )\n",
    "        sn_tokens = utils.lowercase_and_tokenize(\n",
    "            info.satellite_preparation_result.prepared_text\n",
    "        )\n",
    "        assert len(sn_tokens) > 0\n",
    "\n",
    "        reason = None\n",
    "        augmented_sn_text = info.satellite_preparation_result.prepared_text\n",
    "\n",
    "        if nucleus_tokens[0] == \"but\":\n",
    "            reason = RuleExplanation01.reasons[\"N_STARTS_WITH_BUT\"]\n",
    "        elif (\n",
    "            nucleus_tokens[0] == \"if\"\n",
    "                and (\n",
    "                    info.nucleus_info.relation is None\n",
    "                        or utils.get_relation_type(\n",
    "                            info.nucleus_info.relation.left_child\n",
    "                        ) != \"Condition\"\n",
    "                )\n",
    "        ):\n",
    "            reason = RuleExplanation01.reasons[\"N_STARTS_WITH_IF\"]       \n",
    "        elif \"because\" in nucleus_tokens:\n",
    "            reason = RuleExplanation01.reasons[\"N_CONTAINS_BECAUSE\"]\n",
    "        elif sn_tokens[0] == 'but':\n",
    "            reason = RuleExplanation01.reasons[\"SN_STARTS_WITH_BUT\"]\n",
    "        elif \"because\" in set(sn_tokens):\n",
    "            reason = RuleExplanation01.reasons[\"SN_CONTAINS_BECAUSE\"]\n",
    "        else:\n",
    "            satellite_text = preparation.clean(\n",
    "                text[\n",
    "                    info.satellite_info.segment.start:info.satellite_info.segment.end\n",
    "                ]\n",
    "            )\n",
    "            utils.print_if_verbose(f\"Satellite:\\n{satellite_text}\", verbose)\n",
    "            it_make_parse_result = parse_it_makes(word_tokenize(satellite_text))\n",
    "            utils.print_if_verbose(it_make_parse_result, verbose)\n",
    "            if it_make_parse_result.success:\n",
    "                reason = RuleExplanation01.reasons[\"SN_STARTS_WITH_IT_MAKES\"]\n",
    "                assert it_make_parse_result.subject is not None\n",
    "                assert it_make_parse_result.verb is not None\n",
    "                assert it_make_parse_result.rest is not None\n",
    "                augmented_sn_text = preparation.clean(\n",
    "                        \" \".join(\n",
    "                        [\n",
    "                            it_make_parse_result.subject, \n",
    "                            it_make_parse_result.verb, \n",
    "                            it_make_parse_result.rest\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        if reason is not None:\n",
    "            utils.print_if_verbose(reason.explanation, verbose)\n",
    "            final_nucleus_text, final_sn_text = self._finalise_statement_parts(\n",
    "                info.nucleus_preparation_result.prepared_text,\n",
    "                augmented_sn_text,\n",
    "                verbose\n",
    "            )\n",
    "            return self._generate_statement(\n",
    "                final_nucleus_text, \n",
    "                \" because \", \n",
    "                final_sn_text, \n",
    "                relation, \n",
    "                info.nucleus_proximity,\n",
    "                self.name,\n",
    "                reason,\n",
    "                verbose\n",
    "            )\n",
    "        else:\n",
    "            utils.print_if_verbose(\"None of the conditions were met.\", verbose)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But Wang has got used to it and can see the benefits now .  \" I used to speak too little .  But being a team leader means you have to talk a lot .  You could even call me an excellent speaker today . \"  \n",
      "Nucleus is on the left.\n",
      "Nucleus's depth <= 100.\n",
      "Parsing result:\n",
      "(ROOT\n",
      "  (S ('' '')\n",
      "    (NP (CC But))\n",
      "    (ADVP (NNP Wang))\n",
      "    (VP\n",
      "      (VP (VBZ has)\n",
      "        (VP (VBN got)\n",
      "          (S\n",
      "            (VP (VBN used)\n",
      "              (PP (TO to)\n",
      "                (NP (PRP it)))))))\n",
      "      (CC and)\n",
      "      (VP (MD can)\n",
      "        (VP (VB see)\n",
      "          (NP (DT the) (NNS benefits))\n",
      "          (ADVP (RB now)))))\n",
      "    (. .) ('' '')))\n",
      "\n",
      "Constituencies:\n",
      "    type  start  end  depth\n",
      "0     ''      0    1      2\n",
      "1     CC      1    2      3\n",
      "2     NP      1    2      2\n",
      "3    NNP      2    3      3\n",
      "4   ADVP      2    3      2\n",
      "5    VBZ      3    4      4\n",
      "6    VBN      4    5      5\n",
      "7    VBN      5    6      7\n",
      "8     TO      6    7      8\n",
      "9    PRP      7    8      9\n",
      "10    NP      7    8      8\n",
      "11    PP      6    8      7\n",
      "12    VP      5    8      6\n",
      "13     S      5    8      5\n",
      "14    VP      4    8      4\n",
      "15    VP      3    8      3\n",
      "16    CC      8    9      3\n",
      "17    MD      9   10      4\n",
      "18    VB     10   11      5\n",
      "19    DT     11   12      6\n",
      "20   NNS     12   13      6\n",
      "21    NP     11   13      5\n",
      "22    RB     13   14      6\n",
      "23  ADVP     13   14      5\n",
      "24    VP     10   14      4\n",
      "25    VP      9   14      3\n",
      "26    VP      3   14      2\n",
      "27     .     14   15      2\n",
      "28    ''     15   16      2\n",
      "29     S      0   16      1\n",
      "30  ROOT      0   16      0\n",
      "\n",
      "Sentence starts at 1044.\n",
      "Boundaries: (1, 8, 8, 15)\n",
      "Left and right VP boundaries: (3, 8), (9, 14)\n",
      "Umbrella VPs:\n",
      "   type  start  end  depth\n",
      "26   VP      3   14      2\n",
      "Nucleus's (left) nucleus doesn't contain '.', '!', '?', or ';'. Nucleus's right subsegment starts 'and' and its verb belongs to the same subject.\n",
      "Will use only sub-nucleus.\n",
      "Satellite's nucleus is on the left.\n",
      "Nuclei proximity is NucleusProximity.NEAR\n",
      "Satellite's (left) nucleus contains '.', '!', '?', or ';'.\n",
      "Will use the whole segment.\n",
      "Text extracted from the satellite:\n",
      "\" I used to speak too little.  But being a team leader means you have to talk a lot.  You could even call me an excellent speaker today. \"\n",
      "Satellite's nucleus text: \n",
      "\" I used to speak too little.  But being a team leader means you have to talk a lot.  You could even call me an excellent speaker today. \"\n",
      "Nucleus starts with 'but'.\n",
      "Taking the last sentence and resolving pronouns:\n",
      "But Wang has got used to it \n",
      "---> \n",
      "Wang has got used to it.\n",
      "Taking the first sentence and removing leading words:\n",
      "-- syntactic parsing result\n",
      " (ROOT\n",
      "  (S ('' '')\n",
      "    (NP (PRP I))\n",
      "    (VP (VBD used)\n",
      "      (S\n",
      "        (VP (TO to)\n",
      "          (VP (VB speak)\n",
      "            (ADJP (RB too) (JJ little))))))\n",
      "    (. .)))\n",
      "No tokens before the first NP will be removed because the sentence is either empty or starts with if/when/as, quotation mark,or an imperative verb.\n",
      "\" I used to speak too little.  But being a team leader means you have to talk a lot.  You could even call me an excellent speaker today. \" \n",
      "---> \n",
      "''I used to speak little.''\n",
      "\n",
      "RESULT:\n",
      "{\n",
      "  \"statement_text\": \"Wang has got used to it because ''I used to speak little.''\",\n",
      "  \"nucleus\": \"Wang has got used to it\",\n",
      "  \"connective\": \" because \",\n",
      "  \"satellite_nucleus\": \"''I used to speak little.''\",\n",
      "  \"left_boundary\": 1048,\n",
      "  \"right_boundary\": 1251,\n",
      "  \"split_point\": 1108,\n",
      "  \"nucleus_proximity\": \"near\",\n",
      "  \"rule\": \"explanation_01\",\n",
      "  \"reason\": [\n",
      "    1,\n",
      "    \"Nucleus starts with 'but'.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" and \"__file__\" not in globals():\n",
    "    rule = RuleExplanation01()\n",
    "\n",
    "    with open(\"../parsed/race/test/middle/1.txt.tree\", \"rt\") as f:\n",
    "        tree_text = f.read()\n",
    "\n",
    "    text, relations = relation_extraction.read_relations(\n",
    "        tree_text.replace(\"<s>\", \"\").replace(\"<P>\", \"\")\n",
    "    )\n",
    "\n",
    "    expl = relations[\"Explanation\"][1] # for generating just 1 statement\n",
    "    print(text[expl.left.start:expl.right.end])\n",
    "\n",
    "    statement = rule.generate_statement(text, expl, verbose=True)\n",
    "    print(\"\\nRESULT:\")\n",
    "    print(json.dumps(statement._asdict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"''I used to speak little.''\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.take_first_sentence_and_remove_leading_words(\"\\\" I used to speak too little.  But being a team leader means you have to talk a lot.  You could even call me an excellent speaker today. \\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"''I used to speak little.''\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.fix_quotes(\"''I used to speak little.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
