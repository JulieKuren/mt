{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.tokenize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALTERNATIVES_XLSX_PATH = (\n",
    "    \"/Users/YK/mt/project/statements_7/paraphrased_test-middle_1021ac63.xlsx\"\n",
    ")\n",
    "RACE_PART = \"test/middle\"\n",
    "RACE_DIR = \"/Users/YK/mt/RACE\"\n",
    "OUTPUT_DIR = os.path.join(\"/Users/YK/mt/project/generated_rce/\", RACE_PART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reason_scores = pd.read_csv(\n",
    "    \"../ranking.csv\", header=None\n",
    ").rename(\n",
    "    columns={0: \"reason\", 1: \"score\"}\n",
    ")\n",
    "reason_scores[\"score\"] = reason_scores.score.apply(\n",
    "    lambda s: s.replace(\",\", \".\")\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ALTERNATIVES_XLSX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Common pattern ( -Explanation->Condition).',\n",
       " 'Common pattern (Elaboration-JOINT).'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(reason_scores.reason) - set(df[\"reason\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Common pattern (Condition-Explanation).', 'Common pattern (Nucleus=NN- ).'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df[\"reason\"]) - set(reason_scores.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, reason_scores, on=\"reason\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_race(text_no):\n",
    "    with open(os.path.join(RACE_DIR, RACE_PART, f\"{text_no}.txt\"), \"rt\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swap(array, i_1, i_2):\n",
    "    buf = array[i_1]\n",
    "    array[i_1] = array[i_2]\n",
    "    array[i_2] = buf\n",
    "    \n",
    "    \n",
    "def coalesce(value, default_value):\n",
    "    if pd.isnull(value):\n",
    "        return default_value\n",
    "    else:\n",
    "        return value\n",
    "    \n",
    "    \n",
    "def generate_rce(\n",
    "    true_statement, \n",
    "    before_alternatives, \n",
    "    nested_alternatives, \n",
    "    after_alternatives,\n",
    "    swap_first_two,\n",
    "    human_input_pos,\n",
    "    true_statement_pos\n",
    "):\n",
    "    options = (\n",
    "        list(\n",
    "            coalesce(before_alternatives, tuple())\n",
    "                + coalesce(nested_alternatives, tuple())\n",
    "                + coalesce(after_alternatives, tuple())\n",
    "        )[:2]\n",
    "            + [\"HUMAN_INPUT\", true_statement]\n",
    "    )\n",
    "    if len(options) < 4:\n",
    "        return None\n",
    "    else:\n",
    "        if swap_first_two:\n",
    "            swap(options, 0, 1)\n",
    "        swap(options, human_input_pos, 2)        \n",
    "        swap(options, true_statement_pos, 3)\n",
    "        return {\n",
    "            \"answer\": [\"A\", \"B\", \"C\", \"D\"][true_statement_pos],\n",
    "            \"options\": options\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df[\n",
    "    [\n",
    "        \"text_no\", \n",
    "        \"true_statement\", \n",
    "        \"nuclei_hash\", \n",
    "        \"synonym_paraphrased_alternative_statement\",\n",
    "        \"position\"\n",
    "    ]\n",
    "].pivot_table(\n",
    "    values=\"synonym_paraphrased_alternative_statement\",\n",
    "    index=[\"text_no\", \"true_statement\", \"nuclei_hash\"],\n",
    "    columns=\"position\",\n",
    "    aggfunc=tuple\n",
    ")\n",
    "grouped.columns.name = None\n",
    "grouped = grouped.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped[\"swap_first_two\"] = np.random.rand(len(grouped)) < 0.5\n",
    "grouped[\"human_input_pos\"] = np.random.choice(range(3), len(grouped))\n",
    "grouped[\"true_statement_pos\"] = np.random.choice(range(4), len(grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = pd.merge(\n",
    "    grouped,\n",
    "    df[\n",
    "        [\"true_statement\", \"synonym_paraphrased_true_statement\"]\n",
    "    ].groupby(\"true_statement\").head(1),\n",
    "    on=\"true_statement\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped[\"rce\"] = grouped.apply(\n",
    "    lambda row: generate_rce(\n",
    "        row.synonym_paraphrased_true_statement,\n",
    "        row.before,\n",
    "        row.nested,\n",
    "        row.after,\n",
    "        row.swap_first_two,\n",
    "        row.human_input_pos,\n",
    "        row.true_statement_pos\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text_no', 'true_statement', 'nuclei_hash', 'after', 'before', 'nested',\n",
       "       'swap_first_two', 'human_input_pos', 'true_statement_pos',\n",
       "       'synonym_paraphrased_true_statement', 'rce'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(\n",
    "    grouped.loc[~grouped.rce.isnull()],\n",
    "    pd.merge(\n",
    "        df.groupby(\n",
    "            [\"true_statement\"]\n",
    "        ).reason.first().reset_index(),\n",
    "        reason_scores,\n",
    "        on=\"reason\"\n",
    "    ),\n",
    "    on=[\"true_statement\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text_no', 'true_statement', 'nuclei_hash', 'after', 'before', 'nested',\n",
       "       'swap_first_two', 'human_input_pos', 'true_statement_pos',\n",
       "       'synonym_paraphrased_true_statement', 'rce', 'reason', 'score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rce_df = merged[[\"text_no\", \"nuclei_hash\", \"rce\", \"score\"]].sort_values(\n",
    "    by=\"score\", ascending=False\n",
    ").groupby(\n",
    "    [\"text_no\", \"nuclei_hash\"]\n",
    ").head(\n",
    "    1\n",
    ").reset_index(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_rce(rce_group):\n",
    "    generated_answers = []\n",
    "    generated_options = []\n",
    "    for rce in rce_group:\n",
    "        generated_answers.append(rce[\"answer\"])\n",
    "        generated_options.append(rce[\"options\"])\n",
    "    return {\n",
    "        \"generated_answers\": generated_answers,\n",
    "        \"generated_options\": generated_options\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for text_no, group in rce_df.sort_values(\n",
    "    by=\"score\", ascending=False\n",
    ").groupby(by=\"text_no\"):\n",
    "    race = load_race(text_no)\n",
    "    race_n_exercises = len(race[\"answers\"])\n",
    "    if len(group) >= 1: # min(2, race_n_exercises):\n",
    "        output = {\n",
    "            \"race\": race,\n",
    "            \"generated\": collect_rce(list(group.iloc[:race_n_exercises].rce))\n",
    "        }\n",
    "        with open(os.path.join(OUTPUT_DIR, f\"{text_no}.rce.txt\"), \"wt\") as f:\n",
    "            json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rce_to_str(text_no):\n",
    "    output_chunks = []\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{text_no}.rce.txt\"), \"rt\") as f:\n",
    "        rce = json.loads(f.read())\n",
    "    output_chunks.append(f\"TEXT No.{text_no}:\\n\\n{rce['race']['article']}\\n\\n\")\n",
    "    output_chunks.append(f\"GENERATED QUESTIONS:\\n\\n\")\n",
    "    for i, options in enumerate(rce[\"generated\"][\"generated_options\"]):\n",
    "        output_chunks.append(f\"{i + 1}. Which of the following is true?\\n\")\n",
    "        answer = rce['generated']['generated_answers'][i]\n",
    "        block = []\n",
    "        for j, option in enumerate(options):\n",
    "            current_letter = ['A', 'B', 'C', 'D'][j]\n",
    "#             is_true = current_letter == answer\n",
    "#             output_chunks.append(\n",
    "#                 f\"Statement #{j + 1} ({is_true}):\\n{option}\\n\"\n",
    "#             )\n",
    "            block.append(f\"{current_letter}. {option}\")\n",
    "        output_chunks.append(\"\\n\".join(block))\n",
    "        output_chunks.append(\"\")\n",
    "        output_chunks.append(f\"Answer: {answer}\")\n",
    "        output_chunks.append(\"\")\n",
    "    return \"\\n\".join(output_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for text_no in rce_df.text_no.unique():\n",
    "    file_path = os.path.join(OUTPUT_DIR, f\"{text_no}.rce.txt\")\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"rt\") as f:\n",
    "            rce = json.loads(f.read())\n",
    "        result.append((text_no, len(rce[\"generated\"][\"generated_answers\"])))\n",
    "rce_stats_df = pd.DataFrame(result, columns=[\"text_no\", \"n_questions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    53\n",
       "2    10\n",
       "3     2\n",
       "Name: n_questions, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rce_stats_df.n_questions.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating xlsx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordered_text_numbers = list(\n",
    "    rce_stats_df.sort_values(\n",
    "        by=\"n_questions\", ascending=False\n",
    "    ).text_no\n",
    ")\n",
    "first_tier_text_numbers = ordered_text_numbers[:12]\n",
    "second_tier_text_number = ordered_text_numbers[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2518, 3797, 7312, 1675, 1597, 6673, 3010, 2084, 7085, 4227, 2229, 432]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_tier_text_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xlsx_rce(text_no):\n",
    "    with open(os.path.join(OUTPUT_DIR, f\"{text_no}.rce.txt\"), \"rt\") as f:\n",
    "        rce = json.loads(f.read())\n",
    "    rows = [f\"Text No.{text_no}\", rce[\"race\"][\"article\"], \"\"]\n",
    "    letters = ['A', 'B', 'C', 'D']\n",
    "    for i, options in enumerate(rce[\"generated\"][\"generated_options\"]):\n",
    "        rows.append(f\"Question No.{i + 1}\")\n",
    "        for j, option in enumerate(options):\n",
    "            rows.append(f\"({letters[j]}) {option}\")\n",
    "        rows.append(\"\")\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_xlsx(text_numbers, output_dir, file_no):\n",
    "    rows = []\n",
    "    for text_no in text_numbers:\n",
    "        rows.extend(create_xlsx_rce(text_no))\n",
    "    df = pd.DataFrame(rows, columns=[\"-\"])\n",
    "    df[\"Is it true?\"] = None\n",
    "    df[\"Is it grammatically correct?\"] = None\n",
    "    df[\"How sure were you with the answer?\"] = None\n",
    "    df[\"How clear and concise is the statement?\"] = None\n",
    "    df[\"How sensible was the statement?\"] = None\n",
    "    df[\"How easy was it to answer the question?\"] = None\n",
    "    df[\"How important is the information asked in the statement?\"] = None\n",
    "    df.to_excel(os.path.join(output_dir, f\"{file_no}.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xlsx_output_dir = os.path.join(OUTPUT_DIR, \"excel_files\")\n",
    "os.makedirs(xlsx_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_xlsx([2518, 3436, 2512], xlsx_output_dir, 1)\n",
    "save_xlsx([3797, 2299, 357], xlsx_output_dir, 2)\n",
    "for file_no in range(3, 13):\n",
    "    save_xlsx(\n",
    "        (\n",
    "            [first_tier_text_numbers[file_no - 1]]\n",
    "                + second_tier_text_number[\n",
    "                    (4 + (file_no - 3) * 3):(4 + (file_no - 3) * 3) + 3\n",
    "                ]\n",
    "        ),\n",
    "        xlsx_output_dir,\n",
    "        file_no\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rce_strings = [\n",
    "    rce_to_str(text_no) \n",
    "    for text_no in rce_stats_df.loc[rce_stats_df.n_questions >= 2].text_no\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(OUTPUT_DIR, \"rce-2+q.txt\"), \"wt\") as f:\n",
    "    f.write(\"\\n\\n\\n\".join(rce_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT No.3797:\n",
      "\n",
      "Once a tiger was in a cage . Soon a good man went by. As soon as the tiger saw the man, the tiger began to cry. \"Please! Please!\" the tiger called. \"Please, let me out.\" \"No,\" said the good man. \"If I do, you will eat me.\" \"I will not eat you,\" the tiger said. \"Please let me out.\"\n",
      "The good man believed the tiger. He opened the door of the cage. The tiger jumped out. \"How silly you are,\" the tiger laughed. \"Now I am going to eat you.\" \"Wait!\" the man cried. \"You ought not to eat me. Let us ask others what they think.\" \"You may ask three others. \" the tiger said.\n",
      "The good man asked a tree. The tree said, \"I give shade  . And yet I am cut down. Let the tiger eat you.\"\n",
      "Next, the good man asked a bird. The bird said, \"I hurt no one. Yet people hunt and kill me. Let the tiger eat you.\"\n",
      "The last one that the good man asked was a road. The road said, \"I don't care if the tiger eats you. People could not get along too well without me. Yet all day and all night people step on me without even a 'thank you'.\"\n",
      "The tiger was ready to eat the good man. Just then a dog came by. \"What is happening?\"\n",
      "asked the dog. The man told the dog the whole story.\n",
      "\"I don't understand,\" said the dog. \"The tiger wants to eat you because you put him in a cage?\"\n",
      "\"No, no,\" said the man. \"Some other men put him in a cage.\"\n",
      "\"Oh,\" the dog said. \"He is going to eat you because you do not have a cage.\"\n",
      "\"Silly dog!\" the tiger cried. \"Don't you understand? I was in the cage. This man let me out.\"\n",
      "\"Oh, I see,\" the dog said. \"When the man was in the cage, you let him out.\"\n",
      "\"I was in the cage!\" the tiger cried. \"In this way!\" with that, he jumped back into the cage.\n",
      "At once, the dog closed the door of the cage. \"Oh,\" the dog laughed. \"At last I understand!\"\n",
      "The good man and the dog walked off. The tiger looked sad in the cage. If he waited long enough, perhaps another good man would come by.\n",
      "\n",
      "\n",
      "GENERATED QUESTIONS:\n",
      "\n",
      "\n",
      "1. Which of the following is true?\n",
      "\n",
      "A. HUMAN_INPUT\n",
      "B. The tiger stated, and let us ask others what they think.\n",
      "C. The tiger stated, and the satisfactory man asked a tree.\n",
      "D. The tiger stated, and the bird stated, I damaged no one.\n",
      "\n",
      "Answer: C\n",
      "\n",
      "2. Which of the following is true?\n",
      "\n",
      "A. The tiger jumped out. Moreover, ''How silly you are,'' the tiger laughed.\n",
      "B. The tiger jumped out. Moreover, ''I will not eat you,'' the tiger stated.\n",
      "C. HUMAN_INPUT\n",
      "D. The tiger jumped out. Moreover, the bird stated, I injured no one.\n",
      "\n",
      "Answer: A\n",
      "\n",
      "3. Which of the following is true?\n",
      "\n",
      "A. The tiger stated. That is why the wonderful man stated let us ask others what they think.\n",
      "B. The tiger stated. That is why the excellent man stated the bird stated, I damaged no one.\n",
      "C. HUMAN_INPUT\n",
      "D. The tiger stated. That is why the satisfactory man stated \"the fine man asked a tree.\"\n",
      "\n",
      "Answer: D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rce_to_str(3797))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unpaired quotes need to be removed\n",
    "# punctuation must be a part of the nucleus not a connective"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
